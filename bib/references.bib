%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Bei Phillips at 2020-07-02 22:36:48 -0600 


%% Saved with string encoding Unicode (UTF-8) 




@article{HassanFluke2011,
	Author = {Amr Hassan and Christopher J. Fluke},
	Issn = {1448-6083},
	Journal = {Publications of the Astronomical Society of Australia},
	Number = {2},
	Pages = {150--170},
	Publisher = {Cambridge University Press (CUP)},
	Title = {Scientific Visualization in Astronomy: Towards the Petascale Astronomy Era},
	Volume = {28},
	Year = {2011},
  Series = {PASA},
  DOI = {10.1071/AS10031},
  Abstract = {Astronomy is entering a new era of discovery, coincident with the establishment of new facilities for observation and simulation that will routinely generate petabytes of data. While an increasing reliance on automated data analysis is anticipated, a critical role will remain for visualization-based knowledge discovery. We have investigated scientific visualization applications in astronomy through an examination of the literature published during the last two decades. We identify the two most active fields for progress - visualization of large-N particle data and spectral data cubes - discuss open areas of research, and introduce a mapping between astronomical sources of data and data representations used in general purpose visualization tools. We discuss contributions using high performance computing architectures (e.g: distributed processing and GPUs), collaborative astronomy visualization, the use of workflow systems to store metadata about visualization parameters, and the use of advanced interaction devices. We examine a number of issues that may be limiting the spread of scientific visualization research in astronomy and identify six grand challenges for scientific visualization research in the Petascale Astronomy Era.},
  keywords = {type: survey}}

@article{LipsaLarameeCox2012,
	Author = {Dan R. Lipşa and Robert S. Laramee and Simon J. Cox and Jonathan C. Roberts and Rick Walker and Michelle A. Borkin and Hanspeter Pfister},
	Journal = {Computer Graphics Forum},
	Number = {8},
	Pages = {2317-2347},
	Title = {Visualization for the Physical Sciences},
	Volume = {31},
	Year = {2012},
  Series = {CGF},
  DOI = {10.1111/j.1467-8659.2012.03184.x},
  Abstract = {Close collaboration with other scientific fields is an important goal for the visualization community. Yet engaging in a scientific collaboration can be challenging. The physical sciences, namely astronomy, chemistry, earth sciences and physics, exhibit an extensive range of research directions, providing exciting challenges for visualization scientists and creating ample possibilities for collaboration. We present the first survey of its kind that provides a comprehensive view of existing work on visualization for the physical sciences. We introduce novel classification schemes based on application area, data dimensionality and main challenge addressed, and apply these classifications to each contribution from the literature. Our survey helps in understanding the status of current research and serves as a useful starting point for those interested in visualization for the physical sciences.},
  keywords = {type: survey}}





@article{GoodmanBorkinRobitaille2018,
	Author = {Alyssa A. Goodman and Michelle A. Borkin and Thomas P. Robitaille},
	Journal = {arXiv e-prints},
	Month = {may},
	Pages = {arXiv:1805.11300},
	Title = {New Thinking on, and with, Data Visualization},
	Year = {2018},
  Series = {arXiv}
  Abstract = {As the complexity and volume of datasets have increased along with the capabilities of modular, open-source, easy-to-implement, visualization tools, scientists' need for, and appreciation of, data visualization has risen too. Until recently, scientists thought of the "explanatory" graphics created at a research project's conclusion as "pretty pictures" needed only for journal publication or public outreach. The plots and displays produced during a research project - often intended only for experts - were thought of as a separate category, what we here call "exploratory" visualization. In this view, discovery comes from exploratory visualization, and explanatory visualization is just for communication. Our aim in this paper is to spark conversation amongst scientists, computer scientists, outreach professionals, educators, and graphics and perception experts about how to foster flexible data visualization practices that can facilitate discovery and communication at the same time. We present an example of a new finding made using the glue visualization environment to demonstrate how the border between explanatory and exploratory visualization is easily traversed. The linked-view principles as well as the actual code in glue are easily adapted to astronomy, medicine, and geographical information science - all fields where combining, visualizing, and analyzing several high-dimensional datasets yields insight. Whether or not scientists can use such a flexible "undisciplined" environment to its fullest potential without special training remains to be seen. We conclude with suggestions for improving the training of scientists in visualization practices, and of computer scientists in the iterative, non-workflow-like, ways in which modern science is carried out.},
  keywords = type: multi-field vis}

@article{BerrimanGood2017,
	Author = {G. Bruce Berriman and J. C. Good},
	Issn = {1538-3873},
	Journal = {Publications of the Astronomical Society of the Pacific},
	Month = {Apr},
	Number = {975},
	Pages = {058006},
	Publisher = {IOP Publishing},
	Title = {The Application of the Montage Image Mosaic Engine to the Visualization of Astronomical Images},
	Volume = {129},
	Year = {2017},
  DOI = {10.1088/1538-3873/aa5456},
  Series = {PASP},
  abstract = {The Montage Image Mosaic Engine was designed as a scalable toolkit, written in C for performance and portability across *nix platforms, that assembles FITS images into mosaics. This code is freely available and has been widely used in the astronomy and IT communities for research, product generation, and for developing next-generation cyber-infrastructure. Recently, it has begun finding applicability in the field of visualization. This development has come about because the toolkit design allows easy integration into scalable systems that process data for subsequent visualization in a browser or client. The toolkit it includes a visualization tool suitable for automation and for integration into Python: mViewer creates, with a single command, complex multi-color images overlaid with coordinate displays, labels, and observation footprints, and includes an adaptive image histogram equalization method that preserves the structure of a stretched image over its dynamic range. The Montage toolkit contains functionality originally developed to support the creation and management of mosaics, but which also offers value to visualization: a background rectification algorithm that reveals the faint structure in an image; and tools for creating cutout and downsampled versions of large images. Version 5 of Montage offers support for visualizing data written in HEALPix sky-tessellation scheme, and functionality for processing and organizing images to comply with the TOAST sky-tessellation scheme required for consumption by the World Wide Telescope (WWT). Four online tutorials allow readers to reproduce and extend all the visualizations presented in this paper.},
  keywords = type: multi-field vis}

@article{ScherzingerBrixDrees2017,
	Author = {Aaron Scherzinger and Tobias Brix and Dominik Drees and Andreas Völker and Kiril Radkov and Niko Santalidis and Alexander Fieguth and Klaus H. Hinrichs},
	Journal = {IEEE Computer Graphics and Applications},
	Number = {2},
	Pages = {80-89},
	Title = {Interactive Exploration of Cosmological Dark-Matter Simulation Data},
	Volume = {37},
	Year = {2017},
  DOI = {10.1109/MCG.2017.20},
  Series = {IEEE CGA},
  Abstract = {The winning entry of the 2015 IEEE Scientific Visualization Contest, this article describes a visualization tool for cosmological data resulting from dark-matter simulations. The proposed system helps users explore all aspects of the data at once and receive more detailed information about structures of interest at any time. Moreover, novel methods for visualizing and interactively exploring dark-matter halo substructures are proposed.},
  keywords = type: multi-field vis}

@inproceedings{BockPembrokeMays2015,
	Author = {Alexander Bock and A. Pembroke and M. L. Mays and L. Rastaetter and T. Ropinski and Anders Ynnerman},
	Booktitle = {2015 IEEE Scientific Visualization Conference (SciVis)},
	Pages = {17-24},
	Title = {Visual verification of space weather ensemble simulations},
	Year = {2015},
  DOI = {10.1109/SciVis.2015.7429487},
  Abstract = {We propose a system to analyze and contextualize simulations of coronal mass ejections. As current simulation techniques require manual input, uncertainty is introduced into the simulation pipeline leading to inaccurate predictions that can be mitigated through ensemble simulations. We provide the space weather analyst with a multi-view system providing visualizations to: 1. compare ensemble members against ground truth measurements, 2. inspect time-dependent information derived from optical flow analysis of satellite images, and 3. combine satellite images with a volumetric rendering of the simulations. This three-tier workflow provides experts with tools to discover correlations between errors in predictions and simulation parameters, thus increasing knowledge about the evolution and propagation of coronal mass ejections that pose a danger to Earth and interplanetary travel.},
  Series = {IEEE SciVis},
  keywords = type: multi-field vis}

@article{PomaredeCourtoisHoffman2017,
	Author = {Daniel Pomarède, Hélène M. Courtois, Yehuda Hoffman, and R. Brent Tully},
	Issn = {1538-3873},
	Journal = {Publications of the Astronomical Society of the Pacific},
	Month = {Apr},
	Number = {975},
	Pages = {058002},
	Publisher = {IOP Publishing},
	Title = {Cosmography and Data Visualization},
	Volume = {129},
	Year = {2017},
  DOI = {10.1088/1538-3873/aa5b73},
  Series = {PASP},
  abstract = {Cosmography, the study and making of maps of the universe or cosmos, is a field where visual representation benefits from modern three-dimensional visualization techniques and media. At the extragalactic distance scales, visualization is contributing to our understanding of the complex structure of the local universe in terms of spatial distribution and flows of galaxies and dark matter. In this paper, we report advances in the field of extragalactic cosmography obtained using the SDvision visualization software in the context of the Cosmicflows Project. Here, multiple visualization techniques are applied to a variety of data products: catalogs of galaxy positions and galaxy peculiar velocities, reconstructed velocity field, density field, gravitational potential field, velocity shear tensor viewed in terms of its eigenvalues and eigenvectors, envelope surfaces enclosing basins of attraction. These visualizations, implemented as high-resolution images, videos, and interactive viewers, have contributed to a number of studies: the cosmography of the local part of the universe, the nature of the Great Attractor, the discovery of the boundaries of our home supercluster of galaxies Laniakea, the mapping of the cosmic web, and the study of attractors and repellers.},
  keywords = type: multi-field vis}

@article{ShanXieLi2014,
	Author = {Guihua Shan and Maojin Xie and Feng’An Li and Yang Gao and Xuebin Chi},
	Issn = {1875-8975},
	Journal = {Journal of Visualization},
	Month = {Jul},
	Number = {3},
	Pages = {145--156},
	Publisher = {Springer Science and Business Media LLC},
	Title = {Interactive visual exploration of halos in large-scale cosmology simulation},
	Volume = {17},
	Year = {2014},
  Series = {Journal of Visualization},
  Abstract = {Halo is one of the most important basic elements in cosmology simulation, which merges from small clumps to ever larger objects. The processes of halos’ birth and merging play a fundamental role in studying the evolution of large-scale cosmological structure. In this paper, a visual analysis system is developed to interactively identify and explore the evolution histories of thousands of halos. In this system, an intelligent structure-aware selection method in What You See Is What You Get manner is designed to efficiently define user’s interesting region in 3D space with 2D hand-drawn lasso input. Then the exact information of halos within this 3D region is identified by data mining in the merger tree files. To avoid visual clutter, all the halos are projected in 2D space with MDS method. Through the linked view of 3D view and 2D graph, users can interactively explore these halos, including the tracing path and the evolution history tree.},
  DOI = {10.1007/s12650-014-0206-5},
  keywords = type: multi-field vis}

@inproceedings{PrestonGhodsXie2016,
	Author = {A. Preston and R. Ghods and J. Xie and F. Sauer and N. Leaf and K. Ma and E. Rangel and E. Kovacs and K. Heitmann and S. Habib},
	Booktitle = {2016 IEEE Pacific Visualization Symposium (PacificVis)},
	Pages = {48-55},
	Title = {An integrated visualization system for interactive analysis of large, heterogeneous cosmology data},
	Year = {2016},
  Series = {IEEE PacificVis},
  DOI = {10.1109/PACIFICVIS.2016.7465250},
  Abstract = {Cosmological simulations produce a multitude of data types whose large scale makes them difficult to thoroughly explore in an interactive setting. One aspect of particular interest to scientists is the evolution of groups of dark matter particles, or "halos," described by merger trees. However, in order to fully understand subtleties in the merger trees, other data types derived from the simulation must be incorporated as well. In this work, we develop a novel interactive linked-view visualization system that focuses on simultaneously exploring dark matter halos, their hierarchical evolution, corresponding particle data, and other quantitative information. We employ a parallel remote renderer and a local merger tree selection tool so that users can analyze large data sets interactively. This allows scientists to assess their simulation code, understand inconsistencies in extracted data, and intuitively understand simulation behavior on all scales. We demonstrate the effectiveness of our system through a set of case studies on large-scale cosmological data from the HACC (Hardware/Hybrid Accelerated Cosmology Code) simulation framework.},
  keywords = type: multi-field vis}

@article{BockAxelssonCosta2020,
	Author = {Alexander Bock and Emil Axelsson and Jonathas Costa and Gene Payne and Micah Acinapura and Vivian Trakinski and Carter Emmart and Cláudio Silva and Charles Hansen and Anders Ynnerman},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Number = {1},
	Pages = {633-642},
	Title = {OpenSpace: A System for Astrographics},
	Volume = {26},
	Year = {2020},
  Series = {TVCG},
  DOI = {10.1109/TVCG.2019.2934259},
  Abstract = {Human knowledge about the cosmos is rapidly increasing as instruments and simulations are generating new data supporting the formation of theory and understanding of the vastness and complexity of the universe. OpenSpace is a software system that takes on the mission of providing an integrated view of all these sources of data and supports interactive exploration of the known universe from the millimeter scale showing instruments on spacecrafts to billions of light years when visualizing the early universe. The ambition is to support research in astronomy and space exploration, science communication at museums and in planetariums as well as bringing exploratory astrographics to the class room. There is a multitude of challenges that need to be met in reaching this goal such as the data variety, multiple spatio-temporal scales, collaboration capabilities, etc. Furthermore, the system has to be flexible and modular to enable rapid prototyping and inclusion of new research results or space mission data and thereby shorten the time from discovery to dissemination. To support the different use cases the system has to be hardware agnostic and support a range of platforms and interaction paradigms. In this paper we describe how OpenSpace meets these challenges in an open source effort that is paving the path for the next generation of interactive astrographics.},
  keywords = {type: multi-field vis, type: global/local vis}

@article{LucianiCherinkaOliphant2014,
	Author = {T. B. Luciani and B. Cherinka and D. Oliphant and S. Myers and W. M. Wood-Vasey and A. Labrinidis and G. E. Marai},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Number = {7},
	Pages = {1048-1061},
	Title = {Large-Scale Overlays and Trends: Visually Mining, Panning and Zoomingthe Observable Universe},
	Volume = {20},
	Year = {2014},
  Series = {TVCG},
  DOI = {10.1109/TVCG.2014.2312008},
  Abstract = {We introduce a web-based computing infrastructure to assist the visual integration, mining and interactive navigation of large-scale astronomy observations. Following an analysis of the application domain, we design a client-server architecture to fetch distributed image data and to partition local data into a spatial index structure that allows prefix-matching of spatial objects. In conjunction with hardware-accelerated pixel-based overlays and an online cross-registration pipeline, this approach allows the fetching, displaying, panning and zooming of gigabit panoramas of the sky in real time. To further facilitate the integration and mining of spatial and non-spatial data, we introduce interactive trend images-compact visual representations for identifying outlier objects and for studying trends within large collections of spatial objects of a given class. In a demonstration, images from three sky surveys (SDSS, FIRST and simulated LSST results) are cross-registered and integrated as overlays, allowing cross-spectrum analysis of astronomy observations. Trend images are interactively generated from catalog data and used to visually mine astronomy observations of similar type. The front-end of the infrastructure uses the web technologies WebGL and HTML5 to enable cross-platform, web-based functionality. Our approach attains interactive rendering framerates; its power and flexibility enables it to serve the needs of the astronomy community. Evaluation on three case studies, as well as feedback from domain experts emphasize the benefits of this visual approach to the observational astronomy field; and its potential benefits to large scale geospatial visualization in general.},
  keywords = type: multi-field vis}

@article{BurchettAbramovOtto2019,
	Author = {Joseph N. Burchett and David Abramov and Jasmine Otto and Cassia Artanegara and J. Xavier Prochaska and Angus G. Forbes},
	Journal = {Computer Graphics Forum},
	Number = {3},
	Pages = {491-504},
	Title = {IGM-Vis: Analyzing Intergalactic and Circumgalactic Medium Absorption Using Quasar Sightlines in a Cosmic Web Context},
	Volume = {38},
	Year = {2019},
  DOI = {10.1111/cgf.13705},
  Series = {CGF},
  abstract = {Abstract We introduce IGM-Vis, a novel astrophysics visualization and data analysis application for investigating galaxies and the gas that surrounds them in context with their larger scale environment, the Cosmic Web. Environment is an important factor in the evolution of galaxies from actively forming stars to quiescent states with little, if any, discernible star formation activity. The gaseous halos of galaxies (the circumgalactic medium, or CGM) play a critical role in their evolution, because the gas necessary to fuel star formation and any gas expelled from widely observed galactic winds must encounter this interface region between galaxies and the intergalactic medium (IGM). We present a taxonomy of tasks typically employed in IGM/CGM studies informed by a survey of astrophysicists at various career levels, and demonstrate how these tasks are facilitated via the use of our visualization software. Finally, we evaluate the effectiveness of IGM-Vis through two in-depth use cases that depict real-world analysis sessions that use IGM/CGM data.},
  keywords = type: multi-field vis}

@article{Burchett2020,
	doi = {10.3847/2041-8213/ab700c},
	url = {https://doi.org/10.3847%2F2041-8213%2Fab700c},
	year = 2020,
	month = {mar},
	publisher = {American Astronomical Society},
	volume = {891},
	number = {2},
	pages = {L35},
	keywords = {type: unsure},
	Series = {AAS},
	author = {Joseph N. Burchett and Oskar Elek and Nicolas Tejos and J. Xavier Prochaska and Todd M. Tripp and Rongmon Bordoloi and Angus G. Forbes},
	title = {Revealing the Dark Threads of the Cosmic Web},
	journal = {The Astrophysical Journal},
	abstract = {Modern cosmology predicts that matter in our universe today has assembled into a vast network of filamentary structures colloquially termed the “cosmic web.” Because this matter is either electromagnetically invisible (i.e., dark) or too diffuse to image in emission, tests of this cosmic web paradigm are limited. Wide-field surveys do reveal web-like structures in the galaxy distribution, but these luminous galaxies represent less than 10% of baryonic matter. Statistics of absorption by the intergalactic medium (IGM) via spectroscopy of distant quasars support the model yet have not conclusively tied the diffuse IGM to the web. Here, we report on a new method inspired by the Physarum polycephalum slime mold that is able to infer the density field of the cosmic web from galaxy surveys. Applying our technique to galaxy and absorption-line surveys of the local universe, we demonstrate that the bulk of the IGM indeed resides in the cosmic web. From the outskirts of cosmic web filaments, at approximately the cosmic mean matter density (ρ

m
) and ∼5 virial radii from nearby galaxies, we detect an increasing H i absorption signature toward higher densities and the circumgalactic medium, to ∼200ρ

m
. However, the absorption is suppressed within the densest environments, suggesting shock-heating and ionization deep within filaments and/or feedback processes within galaxies.}
}


@article{BreddelsVeljanoski2018,
	Author = {Maarten A. Breddels and Jovan Veljanoski},
	Date-Modified = {2020-07-02 22:30:25 -0600},
	Issn = {1432-0746},
	Journal = {Astronomy \& Astrophysics},
	Month = {Oct},
	Pages = {A13},
	Publisher = {EDP Sciences},
	Title = {{Vaex}: big data exploration in the era of Gaia},
  doi = {10.1051/0004-6361/201732493},
	Volume = {618},
	Year = {2018},
  Series = {A&A},
  Abstract = {We present a new Python library, called vaex, intended to handle extremely large tabular datasets such as astronomical catalogues like the Gaia catalogue, N-body simulations, or other datasets which can be structured in rows and columns. Fast computations of statistics on regular N-dimensional grids allows analysis and visualization in the order of a billion rows per second, for a high-end desktop computer. We use streaming algorithms, memory mapped files, and a zero memory copy policy to allow exploration of datasets larger than memory, for example out-of-core algorithms. Vaex allows arbitrary (mathematical) transformations using normal Python expressions and (a subset of) numpy functions which are “lazily” evaluated and computed when needed in small chunks, which avoids wasting of memory. Boolean expressions (which are also lazily evaluated) can be used to explore subsets of the data, which we call selections. Vaex uses a similar DataFrame API as Pandas, a very popular library, which helps migration from Pandas. Visualization is one of the key points of vaex, and is done using binned statistics in 1d (e.g. histogram), in 2d (e.g. 2d histograms with colourmapping) and 3d (using volume rendering). Vaex is split in in several packages: vaex-core for the computational part, vaex-viz for visualization mostly based on matplotlib, vaex-jupyter for visualization in the Jupyter notebook/lab based in IPyWidgets, vaex-server for the (optional) client-server communication, vaex-ui for the Qt based interface, vaex-hdf5 for HDF5 based memory mapped storage, vaex-astro for astronomy related selections, transformations, and memory mapped (column based) FITS storage.},
  keywords = type: multi-field vis}






@article{ShivashankarPranavNatarajan2016,
	Author = {N. Shivashankar and P. Pranav and V. Natarajan and R. v. d. Weygaert and E. G. P. Bos and S. Rieder},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Number = {6},
	Pages = {1745-1759},
	Title = {Felix: A Topology Based Framework for Visual Exploration of Cosmic Filaments},
	Volume = {22},
	Year = {2016},
  keywords = {type: feature detection},
  Abstract = {The large-scale structure of the universe is comprised of virialized blob-like clusters, linear filaments, sheet-like walls and huge near empty three-dimensional voids. Characterizing the large scale universe is essential to our understanding of the formation and evolution of galaxies. The density range of clusters, walls and voids are relatively well separated, when compared to filaments, which span a relatively larger range. The large scale filamentary network thus forms an intricate part of the cosmic web. In this paper, we describe Felix, a topology based framework for visual exploration of filaments in the cosmic web. The filamentary structure is represented by the ascending manifold geometry of the 2-saddles in the Morse-Smale complex of the density field. We generate a hierarchy of Morse-Smale complexes and query for filaments based on the density ranges at the end points of the filaments. The query is processed efficiently over the entire hierarchical Morse-Smale complex, allowing for interactive visualization. We apply Felix to computer simulations based on the heuristic Voronoi kinematic model and the standard ACDM cosmology, and demonstrate its usefulness through two case studies. First, we extract cosmic filaments within and across cluster like regions in Voronoi kinematic simulation datasets. We demonstrate that we produce similar results to existing structure finders. Second, we extract different classes of filaments based on their density characteristics from the ACDM simulation datasets. Filaments that form the spine of the cosmic web, which exist in high density regions in the current epoch, are isolated using Felix. Also, filaments present in void-like regions are isolated and visualized. These filamentary structures are often over shadowed by higher density range filaments and are not easily characterizable and extractable using other filament extraction methodologies.},
  DOI = {10.1109/TVCG.2015.2452919},
  Series = {TVCG}}

@article{Madura2017,
	Author = {Madura, Thomas I.},
	Issn = {1538-3873},
	Journal = {Publications of the Astronomical Society of the Pacific},
	Month = {Apr},
	Number = {975},
	Pages = {058011},
	Publisher = {IOP Publishing},
	Title = {A Case Study in Astronomical 3D Printing: The Mysterious Eta Carinae},
	Volume = {129},
	Year = {2017},
  keywords = {type: feature detection, type: modeling & simulation},
  Abstract = {Three-dimensional (3D) printing moves beyond interactive 3D graphics and provides an excellent tool for both visual and tactile learners, since 3D printing can now easily communicate complex geometries and full color information. Some limitations of interactive 3D graphics are also alleviated by 3D printable models, including issues of limited software support, portability, accessibility, and sustainability. We describe the motivations, methods, and results of our work on using 3D printing (1) to visualize and understand the η Car Homunculus nebula and central binary system and (2) for astronomy outreach and education, specifically, with visually impaired students. One new result we present is the ability to 3D print full-color models of η Car's colliding stellar winds. We also demonstrate how 3D printing has helped us communicate our improved understanding of the detailed structure of η Car's Homunculus nebula and central binary colliding stellar winds, and their links to each other. Attached to this article are full-color 3D printable files of both a red-blue Homunculus model and the η Car colliding stellar winds at orbital phase 1.045. 3D printing could prove to be vital to how astronomer's reach out and share their work with each other, the public, and new audiences.},
  DOI = {10.1088/1538-3873/129/975/058011},
  Series = {PASP}}


@article{VogtSeitenzahlDopita2017,
	Author = {Vogt, Fr{\'e}d{\'e}ric and Seitenzahl, Ivo and Dopita, Michael and Ruiter, Ashley},
	Journal = {Publications of the Astronomical Society of the Pacific},
	Month = {apr},
	Number = {975},
	Pages = {058012},
	Title = {Linking the X3D pathway to integral field spectrographs: YSNR 1E0102.2-7219 in the SMC as a case study},
	Volume = {129},
	Year = {2017},
  keywords = {type: feature detection},
  Abstract = {The concept of the x3d pathway was introduced by Vogt et al. as a new approach to sharing and publishing three-dimensional structures interactively in online scientific journals. The core characteristics of the x3d pathway are that: (1) it does not rely on specific software, but rather a file format (x3d), (2) it can be implemented using fully open-source tools, and (3) article readers can access the interactive models using most main stream web browsers without the need for any additional plugins. In this article, we further demonstrate the potential of the x3d pathway to visualize data sets from optical integral field spectrographs. We use recent observations of the oxygen-rich young supernova remnant 1E 0102.2-7219 in the Small Magellanic Cloud to implement additional x3dom tools & techniques and expand the range of interactions that can be offered to article readers. In particular, we present a set of javascript functions allowing the creation and interactive handling of clip planes, effectively allowing users to take measurements of distances and angles directly from the interactive model itself.},
  DOI = {10.1088/1538-3873/129/975/058012},
  Series = {PASP}}

@article{ArcandJiangPrice2018,
	Author = {Kimberly Kowal Arcand and Elaine Jiang and Sara Price and Megan Watzke and Tom Sgouros and Peter Edmonds},
	Journal = {Communicating Astronomy with the Public Journal},
	Month = {oct},
	Pages = {17},
	Title = {Walking Through an Exploded Star: Rendering Supernova Remnant Cassiopeia A into Virtual Reality},
	Volume = {24},
	Year = {2018},
  keywords = {type: feature detection},
  Abstract = {Data on the Cassiopeia A supernova remnant from NASA and other sources have been rendered into a three-dimensional
virtual reality (VR) and augmented reality (AR) programme, which is the first of its kind. This data-driven experience of a
supernova remnant allows viewers to take a virtual walk inside the leftovers of a massive star that has exploded, select
parts of the remnant to engage with and access descriptive texts on what the different materials are. This programme is
based on a unique three-dimensional (3D) model of the 340-year old remains of a stellar explosion, made by combining
data from NASA’s Chandra X-ray Observatory, the Spitzer Space Telescope and ground-based facilities. A collaboration
between the Smithsonian Astrophysical Observatory and Brown University allowed the 3D astronomical data collected on
Cassiopeia A to be featured in the VR/AR programme, which is an innovation in digital technologies with public, education
and research-based impacts.},
  Series = {Communicating Astronomy with the Public}}

@article{ArcandJubettWatzke2019,
	Author = {Kimberly Kowal Arcand and April Jubett and Megan Watzke and Sara Price and Kelly Williamson and Peter Edmonds},
	Date-Modified = {2020-07-02 22:33:14 -0600},
	Doi = {10.22323/2.18040201},
	Journal = {Journal of Science Communication},
	Title = {Touching the stars: improving {NASA 3D} printed data sets with blind and visually impaired audiences},
	Year = {2019},
  keywords = {type: feature detection},
  Abstract = {Astronomy has been an inherently visual area of science for millenia, yet a majority of its significant discoveries take place in wavelengths beyond human vision. There are many people, including those with low or no vision, who cannot participate fully in such discoveries if visual media is the primary communication mechanism. Numerous efforts have worked to address equity of accessibility to such knowledge sharing, such as through the creation of three-dimensional (3D) printed data sets. This paper describes progress made through technological and programmatic developments in tactile 3D models using NASA's Chandra X-ray Observatory to improve access to data.},
  Series  = {JCOM}}

@article{DykesHassanGheller2018,
	Author = {Tim Dykes and Amr Hassan and Claudio Gheller and Darren Croton and Mel Krokos},
	Issn = {0035-8711},
	Journal = {Monthly Notices of the Royal Astronomical Society},
	Month = {apr},
	Number = {2},
	Pages = {1495-1507},
	Title = {Interactive 3D visualization for theoretical virtual observatories},
	Volume = {477},
	Year = {2018},
  keywords = {type: feature detection},
  Abstract = {Virtual observatories (VOs) are online hubs of scientific knowledge. They encompass a collection of platforms dedicated to the storage and dissemination of astronomical data, from simple data archives to e-research platforms offering advanced tools for data exploration and analysis. Whilst the more mature platforms within VOs primarily serve the observational community, there are also services fulfilling a similar role for theoretical data. Scientific visualization can be an effective tool for analysis and exploration of data sets made accessible through web platforms for theoretical data, which often contain spatial dimensions and properties inherently suitable for visualization via e.g. mock imaging in 2D or volume rendering in 3D. We analyse the current state of 3D visualization for big theoretical astronomical data sets through scientific web portals and virtual observatory services. We discuss some of the challenges for interactive 3D visualization and how it can augment the workflow of users in a virtual observatory context. Finally we showcase a lightweight client–server visualization tool for particle-based data sets, allowing quantitative visualization via data filtering, highlighting two example use cases within the Theoretical Astrophysical Observatory.},
  DOI = {10.1093/mnras/sty855},
  Series = {MNRAS}}






@article{DiemerFacio2017,
	Author = {Benedikt Diemer and Isaac Facio},
	Journal = {Publications of the Astronomical Society of the Pacific},
	Month = {apr},
	Number = {975},
	Pages = {058013},
	Publisher = {IOP Publishing},
	Title = {The Fabric of the Universe: Exploring the Cosmic Web in 3D Prints and Woven Textiles},
	Volume = {129},
	Year = {2017},
  keywords = {type: modeling & simulation},
  Abstract = {We introduce The Fabric of the Universe, an art and science collaboration focused on exploring the cosmic web of dark matter with unconventional techniques and materials. We discuss two of our projects in detail. First, we describe a pipeline for translating three-dimensional (3D) density structures from N-body simulations into solid surfaces suitable for 3D printing, and present prints of a cosmological volume and of the infall region around a massive cluster halo. In these models, we discover wall-like features that are invisible in two-dimensional projections. Going beyond the sheer visualization of simulation data, we undertake an exploration of the cosmic web as a three-dimensional woven textile. To this end, we develop experimental 3D weaving techniques to create sphere-like and filamentary shapes and radically simplify a region of the cosmic web into a set of filaments and halos. We translate the resulting tree structure into a series of commands that can be executed by a digital weaving machine, and present a large-scale textile installation.},
  DOI = {10.1088/1538-3873/aa6a46},
  Series = {PASP}}

@article{OrlandoPillitteriBocchino2019,
	doi = {10.3847/2515-5172/ab5966},
	url = {https://doi.org/10.3847%2F2515-5172%2Fab5966},
	year = 2019,
	month = {nov},
	publisher = {American Astronomical Society},
	volume = {3},
	number = {11},
	pages = {176},
	author = {Salvatore Orlando and Ignazio Pillitteri and Fabrizio Bocchino and Laura Daricello and Laura Leonardi},
	title = {3DMAP-{VR}, A Project to Visualize Three-dimensional Models of Astrophysical Phenomena in Virtual Reality},
	journal = {Research Notes of the {AAS}},
  series = {AAS},
  keywords = {type: modeling & simulation}
}
@article{KaehlerHahnAbel2012,
	Author = {R. Kaehler and O. Hahn and T. Abel},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Number = {12},
	Pages = {2078-2087},
	Title = {A Novel Approach to Visualizing Dark Matter Simulations},
	Volume = {18},
	Year = {2012},
  keywords = {type: modeling & simulation},
  Abstract = {In the last decades cosmological N-body dark matter simulations have enabled ab initio studies of the formation of structure in the Universe. Gravity amplified small density fluctuations generated shortly after the Big Bang, leading to the formation of galaxies in the cosmic web. These calculations have led to a growing demand for methods to analyze time-dependent particle based simulations. Rendering methods for such N-body simulation data usually employ some kind of splatting approach via point based rendering primitives and approximate the spatial distributions of physical quantities using kernel interpolation techniques, common in SPH (Smoothed Particle Hydrodynamics)-codes. This paper proposes three GPU-assisted rendering approaches, based on a new, more accurate method to compute the physical densities of dark matter simulation data. It uses full phase-space information to generate a tetrahedral tessellation of the computational domain, with mesh vertices defined by the simulation's dark matter particle positions. Over time the mesh is deformed by gravitational forces, causing the tetrahedral cells to warp and overlap. The new methods are well suited to visualize the cosmic web. In particular they preserve caustics, regions of high density that emerge, when several streams of dark matter particles share the same location in space, indicating the formation of structures like sheets, filaments and halos. We demonstrate the superior image quality of the new approaches in a comparison with three standard rendering techniques for N-body simulation data.},
  DOI = {10.1109/TVCG.2012.187},
  Series = {TVCG}}

@article{SteffenKoningWenger2011,
	Author = {W. Steffen and N. Koning and S. Wenger and C. Morisset and M. Magnor},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Number = {4},
	Pages = {454-465},
	Title = {Shape: A 3D Modeling Tool for Astrophysics},
	Volume = {17},
	Year = {2011},
  keywords = {type: modeling & simulation},
  Abstract = {We present a flexible interactive 3D morpho-kinematical modeling application for astrophysics. Compared to other systems, our application reduces the restrictions on the physical assumptions, data type, and amount that is required for a reconstruction of an object's morphology. It is one of the first publicly available tools to apply interactive graphics to astrophysical modeling. The tool allows astrophysicists to provide a priori knowledge about the object by interactively defining 3D structural elements. By direct comparison of model prediction with observational data, model parameters can then be automatically optimized to fit the observation. The tool has already been successfully used in a number of astrophysical research projects.},
  DOI = {10.1109/TVCG.2010.62},
  Series = {TVCG}}

@article{WengerAmentGuthe2012,
	Author = {Stephan Wenger and Marco Ament and Stefan Guthe and Dirk Lorenz and Andreas Tillmann and Daniel Weiskopf and Marcus Magnor},
	Date-Modified = {2020-07-02 22:36:10 -0600},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Number = {12},
	Pages = {2188-2197},
	Title = {Visualization of Astronomical Nebulae via Distributed Multi-{GPU} Compressed Sensing Tomography},
	Volume = {18},
	Year = {2012},
  keywords = {type: modeling & simulation},
  Abstract = {The 3D visualization of astronomical nebulae is a challenging problem since only a single 2D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae. Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach is based on an iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from arbitrary projections. Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a much higher amount of detail and visual variety in the 3D visualization, especially for objects with only approximate symmetry.},
  DOI = {10.1109/TVCG.2012.281},
  Series = {TVCG}}

@article{Taylor2017,
	Author = {R. Taylor},
	Journal = {Publications of the Astronomical Society of the Pacific},
	Month = {jan},
	Number = {972},
	Pages = {028002},
	Publisher = {IOP Publishing},
	Title = {Visualizing Three-dimensional Volumetric Data with an Arbitrary Coordinate System},
	Volume = {129},
	Year = {2017},
  keywords = {type: modeling & simulation},
  Abstract = {Astronomical data does not always use Cartesian coordinates. Both all-sky observational data and simulations of rotationally symmetric systems, such as accretion and protoplanetary disks, may use spherical polar or other coordinate systems. Standard displays rely on Cartesian coordinates, but converting non-Cartesian data into Cartesian format causes distortion of the data and loss of detail. Here, I  demonstrate a method using standard techniques from computer graphics that avoids these problems with three-dimensional data in arbitrary coordinate systems. The method adds minimum computational cost to the display process and is suitable for both realtime, interactive content, and producing fixed rendered images and videos. Proof-of-concept code is provided which works for data in spherical polar coordinates.},
  DOI = {10.1088/1538-3873/129/972/028002},
  Series = {PASP}}

@article{NaimanBorkiewiczChristensen2017,
	Author = {J. P. Naiman and Kalina Borkiewicz and A. J. Christensen},
	Journal = {Publications of the Astronomical Society of the Pacific},
	Month = {apr},
	Number = {975},
	Pages = {058008},
	Publisher = {IOP Publishing},
	Title = {Houdini for Astrophysical Visualization},
	Volume = {129},
	Year = {2017},
  keywords = {type: modeling & simulation},
  Abstract = {The rapid growth in scale and complexity of both computational and observational astrophysics over the past decade necessitates efficient and intuitive methods for examining and visualizing large data sets. Here, we discuss some newly developed tools used to import and manipulate astrophysical data into the three-dimensional visual effects software, Houdini. This software is widely used by visual effects artists, but a recently implemented Python API now allows astronomers to more easily use Houdini as a visualization tool. This paper includes a description of features, workflow, and various example visualizations. The project website, www.ytini.com, is aimed at a scientific audience and contains Houdini tutorials and links to the Python script Bitbucket repository to simplify the process of importing and rendering astrophysical data.},
  DOI = {10.1088/1538-3873/aa51b3},
  Series = {PASP}}

@article{Garate2017,
	Author = {Matías Gárate},
	Journal = {Publications of the Astronomical Society of the Pacific},
	Month = {apr},
	Number = {975},
	Pages = {058010},
	Publisher = {IOP Publishing},
	Title = {Voxel Datacubes for 3D Visualization in Blender},
	Volume = {129},
	Year = {2017},
  keywords = {type: modeling & simulation},
  Abstract = {The growth of computational astrophysics and the complexity of multi-dimensional data sets evidences the need for new versatile visualization tools for both the analysis and presentation of the data. In this work, we show how to use the open-source software Blender as a three-dimensional (3D) visualization tool to study and visualize numerical simulation results, focusing on astrophysical hydrodynamic experiments. With a datacube as input, the software can generate a volume rendering of the 3D data, show the evolution of a simulation in time, and do a fly-around camera animation to highlight the points of interest. We explain the process to import simulation outputs into Blender using the voxel data format, and how to set up a visualization scene in the software interface. This method allows scientists to perform a complementary visual analysis of their data and display their results in an appealing way, both for outreach and science presentations.},
  DOI = {10.1088/1538-3873/129/975/058010},
  Series = {PASP}}

@article{HasenbergerAlves2020,
	Author = {Hasenberger, Birgit and Alves, Jo{\~a}o},
	Date-Modified = {2020-07-02 22:30:04 -0600},
	Issn = {1432-0746},
	Journal = {Astronomy \& Astrophysics},
	Month = {Jan},
	Pages = {A132},
	Publisher = {EDP Sciences},
	Title = {{AVIATOR}: Morphological object reconstruction in 3D},
	Volume = {633},
	Year = {2020},
  keywords = {type: modeling & simulation},
  Abstract = {Reconstructing 3D distributions from their 2D projections is a ubiquitous problem in various scientific fields, particularly so in observational astronomy. In this work, we present a new approach to solving this problem: a Vienna inverse-Abel-transform based object reconstruction algorithm AVIATOR. The reconstruction that it performs is based on the assumption that the distribution along the line of sight is similar to the distribution in the plane of projection, which requires a morphological analysis of the structures in the projected image. The output of the AVIATOR algorithm is an estimate of the 3D distribution in the form of a reconstruction volume that is calculated without the problematic requirements that commonly occur in other reconstruction methods such as symmetry in the plane of projection or modelling of radial profiles. We demonstrate the robustness of the technique to different geometries, density profiles, and noise by applying the AVIATOR algorithm to several model objects. In addition, the algorithm is applied to real data: We reconstruct the density and temperature distributions of two dense molecular cloud cores and find that they are in excellent agreement with profiles reported in the literature. The AVIATOR algorithm is thus capable of reconstructing 3D distributions of physical quantities consistently using an intuitive set of assumptions.},
  DOI = {10.1051/0004-6361/201936095},
  Series = {A&A}}

@article{GrosschedlAlvesMeingast2018,
	Author = {Josefa E. Großschedl and João Alves and Stefan Meingast and Christine Ackerl and Joana Ascenso and Hervé Bouy and Andreas Burkert and Jan Forbrich and Verena Fürnkranz and Alyssa A. Goodman and Álvaro Hacar and Gabor Herbst-Kiss and Charles J. Lada and Irati Larreina and Kieran Leschinski and Marco Lombardi and André Moitinho and Daniel Mortimer and Eleonora Zari},
	Date-Modified = {2020-07-02 22:30:16 -0600},
	Journal = {Astronomy \& Astrophysics},
	Month = {nov},
	Pages = {A106},
	Title = {3D shape of {Orion A} from {Gaia DR2}},
	Volume = {619},
	Year = {2018},
  keywords = {type: modeling & simulation},
  Abstract = {We use the Gaia DR2 distances of about 700 mid-infrared selected young stellar objects in the benchmark giant molecular cloud Orion A to infer its 3D shape and orientation. We find that Orion A is not the fairly straight filamentary cloud that we see in (2D) projection, but instead a cometary-like cloud oriented toward the Galactic plane, with two distinct components: a denser and enhanced star-forming (bent) Head, and a lower density and star-formation quieter ∼75 pc long Tail. The true extent of Orion A is not the projected ∼40 pc but ∼90 pc, making it by far the largest molecular cloud in the local neighborhood. Its aspect ratio (∼30:1) and high column-density fraction (∼45%) make it similar to large-scale Milky Way filaments (“bones”), despite its distance to the galactic mid-plane being an order of magnitude larger than typically found for these structures.},
  DOI = {10.1051/0004-6361/201833901},
  Series = {A&A}}






@article{SagristaJordanMuller2019,
	Author = {Antoni Sagristà and Stefan Jordan and Thomas Müller and Filip Sadlo},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Number = {1},
	Pages = {1070-1079},
	Title = {Gaia Sky: Navigating the Gaia Catalog},
	Volume = {25},
	Year = {2019},
  keywords = {type: global/local vis},
  Abstract = {In this paper, we present Gaia Sky, a free and open-source multiplatform 3D Universe system, developed since 2014 in the Data Processing and Analysis Consortium framework of ESA's Gaia mission. Gaia's data release 2 represents the largest catalog of the stars of our Galaxy, comprising 1.3 billion star positions, with parallaxes, proper motions, magnitudes, and colors. In this mission, Gaia Sky is the central tool for off-the-shelf visualization of these data, and for aiding production of outreach material. With its capabilities to effectively handle these data, to enable seamless navigation along the high dynamic range of distances, and at the same time to provide advanced visualization techniques including relativistic aberration and gravitational wave effects, currently no actively maintained cross-platform, modern, and open alternative exists.},
  DOI = {10.1109/TVCG.2018.2864508},
  Series = {TVCG}}

@article{AxelssonCostaSilva2017,
	Author = {Emil Axelsson and Jonathas Costa and Cláudio Silva and Carter Emmart and Alexander Bock and Anders Ynnerman},
	Journal = {Computer Graphics Forum},
	Number = {3},
	Pages = {459-468},
	Title = {Dynamic Scene Graph: Enabling Scaling, Positioning, and Navigation in the Universe},
	Volume = {36},
	Year = {2017},
  keywords = {type: global/local vis},
  Abstract = {In this work, we address the challenge of seamlessly visualizing astronomical data exhibiting huge scale differences in distance, size, and resolution. One of the difficulties is accurate, fast, and dynamic positioning and navigation to enable scaling over orders of magnitude, far beyond the precision of floating point arithmetic. To this end we propose a method that utilizes a dynamically assigned frame of reference to provide the highest possible numerical precision for all salient objects in a scene graph. This makes it possible to smoothly navigate and interactively render, for example, surface structures on Mars and the Milky Way simultaneously. Our work is based on an analysis of tracking and quantification of the propagation of precision errors through the computer graphics pipeline using interval arithmetic. Furthermore, we identify sources of precision degradation, leading to incorrect object positions in screen‐space and z‐fighting. Our proposed method operates without near and far planes while maintaining high depth precision through the use of floating point depth buffers. By providing interoperability with order‐independent transparency algorithms, direct volume rendering, and stereoscopy, our approach is well suited for scientific visualization. We provide the mathematical background, a thorough description of the method, and a reference implementation.},
  DOI = {10.1111/cgf.13202},
  Series = {CGF}}

@article{BainesGiordanoRacero2016,
	Author = {Deborah Baines amd Fabrizio Giordano and Elena Racero and Jesús Salgado and Belén López Martí and Bruno Merín and María-Henar Sarmiento and Raúl Gutiérrez and Iñaki Ortiz de Landaluce and Ignacio León},
	Journal = {Publications of the Astronomical Society of the Pacific},
	Month = {dec},
	Number = {972},
	Pages = {028001},
	Publisher = {IOP Publishing},
	Title = {Visualization of Multi-mission Astronomical Data with ESASky},
	Volume = {129},
	Year = {2016},
  keywords = {type: global/local vis},
  Abstract = {ESASky is a science-driven discovery portal to explore the multi-wavelength sky and visualize and access multiple astronomical archive holdings. The tool is a web application that requires no prior knowledge of any of the missions involved and gives users world-wide simplified access to the highest-level science data products from multiple astronomical space-based astronomy missions plus a number of ESA source catalogs. The first public release of ESASky features interfaces for the visualization of the sky in multiple wavelengths, the visualization of query results summaries, and the visualization of observations and catalog sources for single and multiple targets. This paper describes these features within ESASky, developed to address use cases from the scientific community. The decisions regarding the visualization of large amounts of data and the technologies used were made to maximize the responsiveness of the application and to keep the tool as useful and intuitive as possible.},
  DOI = {10.1088/1538-3873/129/972/028001},
  Series = {PASP}}

@article{ArgudoFernandezPuertasRuiz2017,
	Author = {M. Argudo-Fernández and S. Duarte Puertas and J. E. Ruiz and J. Sabater and S. Verley and G. Bergond},
	Journal = {Publications of the Astronomical Society of the Pacific},
	Month = {apr},
	Number = {975},
	Pages = {058005},
	Publisher = {IOP Publishing},
	Title = {LSSGalPy: Interactive Visualization of the Large-scale Environment Around Galaxies},
	Volume = {129},
	Year = {2017},
  keywords = {type: global/local vis},
  Abstract = {New tools are needed to handle the growth of data in astrophysics delivered by recent and upcoming surveys. We aim to build open-source, light, flexible, and interactive software designed to visualize extensive three-dimensional (3D) tabular data. Entirely written in the Python language, we have developed interactive tools to browse and visualize the positions of galaxies in the universe and their positions with respect to its large-scale structures (LSS). Motivated by a previous study, we created two codes using Mollweide projection and wedge diagram visualizations, where survey galaxies can be overplotted on the LSS of the universe. These are interactive representations where the visualizations can be controlled by widgets. We have released these open-source codes that have been designed to be easily re-used and customized by the scientific community to fulfill their needs. The codes are adaptable to other kinds of 3D tabular data and are robust enough to handle several millions of objects.},
  DOI = {10.1088/1538-3873/aa5785},
  Series = {PASP}}




@article{WengerLorenzMagnor2013,
author = {Stephan Wenger and Dirk Lorenz and Marcus Magnor},
title = {Fast Image-Based Modeling of Astronomical Nebulae},
journal = {Computer Graphics Forum},
volume = {32},
number = {7},
pages = {93-100},
doi = {10.1111/cgf.12216},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12216},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12216},
abstract = {Abstract Astronomical nebulae are among the most complex and visually appealing phenomena known outside the bounds of the Solar System. However, our fixed vantage point on Earth limits us to a single known view of these objects, and their intricate volumetric structure cannot be recovered directly. Recent approaches to reconstructing a volumetric 3D model use the approximate symmetry inherent to many nebulae, but require several hours of computation time on large multi-GPU clusters. We present a novel reconstruction algorithm based on group sparsity that reaches or even exceeds the quality of prior results while taking only a fraction of the time on a conventional desktop PC, thereby enabling end users in planetariums or educational facilities to produce high-quality content without expensive hardware or manual modeling. In principle, our approach can be generalized to other transparent phenomena with arbitrary types of user-specified symmetries.},
year = {2013}
keywords = {type: modeling & simulation},
series = {CGF}
}


@article{BoussejraUchikiTakeshima2019,
title = aflak: Visual programming environment enabling end-to-end provenance management for the analysis of astronomical datasets,
journal = "Visual Informatics",
volume = "3",
number = "1",
pages = "1 - 8",
year = 2019,
note = "Proceedings of PacificVAST 2019",
issn = "2468-502X",
doi = {10.1016/j.visinf.2019.03.001},
url = "http://www.sciencedirect.com/science/article/pii/S2468502X19300154",
author = {Malik Olivier Boussejra and Rikuo Uchiki and Yuriko Takeshima and Kazuya Matsubayashi and Shunya Takekawa and Makoto Uemura and Issei Fujishiro},
abstract = "This paper describes an extendable graphical framework, aflak, which provides a visualization and provenance management environment for the analysis of multi-spectral astronomical datasets. Via its node editor interface, aflak allows the astronomer to compose transforms on input datasets queryable from public astronomical data repositories, then to export the results of the analysis as Flexible Image Transport System (FITS) files, in a manner such that the full provenance of the output data be preserved and reviewable, and that the exported file be usable by other common astronomical analysis software. FITS is the standard of data interchange in astronomy. By embedding aflak’s provenance data into FITS files, we both achieve interoperability with existing software and full reproducibility of the process by which astronomers make discoveries."
keywords = {type: unsure},
series = {Visual Informatics}
}

@article{Naiman2016,
title = AstroBlend: An astrophysical visualization package for Blender,
journal = "Astronomy and Computing",
volume = "15",
pages = "50 - 60",
year = 2016,
issn = "2213-1337",
doi = {https://doi.org/10.1016/j.ascom.2016.02.002},
url = {http://www.sciencedirect.com/science/article/pii/S2213133716300117},
author = {J. P. Naiman},
keywords = {type: modeling & simulation},
Series = {Astronomy and Computing}
abstract = "The rapid growth in scale and complexity of both computational and observational astrophysics over the past decade necessitates efficient and intuitive methods for examining and visualizing large datasets. Here, I present AstroBlend, an open-source Python library for use within the three dimensional modeling software, Blender. While Blender has been a popular open-source software among animators and visual effects artists, in recent years it has also become a tool for visualizing astrophysical datasets. AstroBlend combines the three dimensional capabilities of Blender with the analysis tools of the widely used astrophysical toolset, yt, to afford both computational and observational astrophysicists the ability to simultaneously analyze their data and create informative and appealing visualizations. The introduction of this package includes a description of features, work flow, and various example visualizations. A website — www.astroblend.com — has been developed which includes tutorials, and a gallery of example images and movies, along with links to downloadable data, three dimensional artistic models, and various other resources."
}